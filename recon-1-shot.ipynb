{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from models import utils as mutils\n",
    "import sampling\n",
    "from sde_lib import VESDE\n",
    "from sampling import (ReverseDiffusionPredictor,\n",
    "                      LangevinCorrector,\n",
    "                      LangevinCorrectorCS)\n",
    "# from models import ncsnpp\n",
    "from itertools import islice\n",
    "from losses import get_optimizer\n",
    "import datasets\n",
    "import time\n",
    "import controllable_generation_TV\n",
    "from utils import restore_checkpoint, fft2, ifft2, show_samples_gray, get_mask, clear\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from models.ema import ExponentialMovingAverage\n",
    "from scipy.io import savemat, loadmat\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import torchvision\n",
    "from models import ncsnpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "# Configurations\n",
    "###############################################\n",
    "problem = 'Fourier_CS_3d_admm_tv'\n",
    "config_name = 'fastmri_knee_320_ncsnpp_continuous'\n",
    "sde = 'VESDE'\n",
    "num_scales = 2000\n",
    "ckpt_num = 95\n",
    "N = num_scales\n",
    "\n",
    "root = './data/MRI/BRATS'\n",
    "vol = 'Brain-1shot'\n",
    "\n",
    "if sde.lower() == 'vesde':\n",
    "  # from configs.ve import fastmri_knee_320_ncsnpp_continuous as configs\n",
    "  configs = importlib.import_module(f\"configs.ve.{config_name}\")\n",
    "  if config_name == 'fastmri_knee_320_ncsnpp_continuous':\n",
    "    ckpt_filename = f\"./exp/ve/{config_name}/checkpoint_{ckpt_num}.pth\"\n",
    "  elif config_name == 'ffhq_256_ncsnpp_continuous':\n",
    "    ckpt_filename = f\"exp/ve/{config_name}/checkpoint_48.pth\"\n",
    "  config = configs.get_config()\n",
    "  config.model.num_scales = num_scales\n",
    "  sde = VESDE(sigma_min=config.model.sigma_min, sigma_max=config.model.sigma_max, N=config.model.num_scales)\n",
    "  sde.N = N\n",
    "  sampling_eps = 1e-5\n",
    "\n",
    "img_size = 240\n",
    "batch_size = 1\n",
    "config.training.batch_size = batch_size\n",
    "predictor = ReverseDiffusionPredictor\n",
    "corrector = LangevinCorrector\n",
    "probability_flow = False\n",
    "snr = 0.16\n",
    "n_steps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for Fourier CS recon\n",
    "mask_type = 'uniform1d'\n",
    "use_measurement_noise = False\n",
    "acc_factor = 2.0\n",
    "center_fraction = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:  cpu\n",
      "device now:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "config.device = torch.device('cpu')\n",
    "print(\"device: \",config.device)\n",
    "\n",
    "import os\n",
    "\n",
    "m_gpu=0\n",
    "torch.cuda.device_count()\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '%d' % m_gpu\n",
    "torch.cuda.set_device(m_gpu)\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.current_device()\n",
    "config.device = torch.device(torch.cuda.current_device())\n",
    "print(\"device now: \",config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device now:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(\"device now: \",config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded checkpoint dir from exp/ve/fastmri_knee_320_ncsnpp_continuous/checkpoint_95.pth\n"
     ]
    }
   ],
   "source": [
    "# ADMM TV parameters\n",
    "lamb_list = [0.005]\n",
    "rho_list = [0.01]\n",
    "\n",
    "random_seed = 0\n",
    "\n",
    "sigmas = mutils.get_sigmas(config)\n",
    "scaler = datasets.get_data_scaler(config)\n",
    "inverse_scaler = datasets.get_data_inverse_scaler(config)\n",
    "score_model = mutils.create_model(config)\n",
    "\n",
    "optimizer = get_optimizer(config, score_model.parameters())\n",
    "ema = ExponentialMovingAverage(score_model.parameters(),\n",
    "                               decay=config.model.ema_rate)\n",
    "state = dict(step=0, optimizer=optimizer,\n",
    "             model=score_model, ema=ema)\n",
    "state = restore_checkpoint(ckpt_filename, state, config.device, skip_sigma=True)\n",
    "ema.copy_to(score_model.parameters())\n",
    "\n",
    "fname_list = sorted(list((Path(root) / vol).glob('*.npy')))\n",
    "all_img = []\n",
    "for fname in tqdm(fname_list):\n",
    "    img = np.load(fname)\n",
    "    img = torch.from_numpy(img)\n",
    "    h, w = img.shape\n",
    "    img = img.view(1, 1, h, w)\n",
    "    all_img.append(img)\n",
    "\n",
    "all_img = torch.cat(all_img, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the volume to be in proper range\n",
    "vmax = all_img.max()\n",
    "all_img /= (vmax + 1e-5)\n",
    "\n",
    "img = all_img.to(config.device)\n",
    "b = img.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda: 0.005\n",
      "rho:    0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [10:15<00:00,  3.25it/s]\n"
     ]
    }
   ],
   "source": [
    "for lamb in lamb_list:\n",
    "    for rho in rho_list:\n",
    "        print(f'lambda: {lamb}')\n",
    "        print(f'rho:    {rho}')\n",
    "        # Specify save directory for saving generated samples\n",
    "        save_root = Path(f'./results/{config_name}/{problem}/{mask_type}/acc{acc_factor}/lamb{lamb}/rho{rho}/{vol}')\n",
    "        save_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        irl_types = ['input', 'recon', 'label']\n",
    "        for t in irl_types:\n",
    "            save_root_f = save_root / t\n",
    "            save_root_f.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        ###############################################\n",
    "        # Inference\n",
    "        ###############################################\n",
    "\n",
    "        # forward model\n",
    "        kspace = fft2(img)\n",
    "\n",
    "        # generate mask\n",
    "        mask = get_mask(torch.zeros(1, 1, h, w), img_size, batch_size,\n",
    "                        type=mask_type, acc_factor=acc_factor, center_fraction=center_fraction)\n",
    "        mask = mask.to(img.device)\n",
    "        mask = mask.repeat(b, 1, 1, 1)\n",
    "\n",
    "        pc_fouriercs = controllable_generation_TV.get_pc_radon_ADMM_TV_mri(sde,\n",
    "                                                                           predictor, corrector,\n",
    "                                                                           inverse_scaler,\n",
    "                                                                           mask=mask,\n",
    "                                                                           lamb_1=lamb,\n",
    "                                                                           rho=rho,\n",
    "                                                                           img_shape=img.shape,\n",
    "                                                                           snr=snr,\n",
    "                                                                           n_steps=n_steps,\n",
    "                                                                           probability_flow=probability_flow,\n",
    "                                                                           continuous=config.training.continuous)\n",
    "\n",
    "        # undersampling\n",
    "        under_kspace = kspace * mask\n",
    "        under_img = torch.real(ifft2(under_kspace))\n",
    "\n",
    "        count = 0\n",
    "        for i, recon_img in enumerate(under_img):\n",
    "            plt.imsave(save_root / 'input' / f'{count}.png', clear(under_img[i]), cmap='gray')\n",
    "            plt.imsave(save_root / 'label' / f'{count}.png', clear(img[i]), cmap='gray')\n",
    "            count += 1\n",
    "\n",
    "        x = pc_fouriercs(score_model, scaler(under_img), measurement=under_kspace)\n",
    "\n",
    "        count = 0\n",
    "        for i, recon_img in enumerate(x):\n",
    "            plt.imsave(save_root / 'input' / f'{count}.png', clear(under_img[i]), cmap='gray')\n",
    "            plt.imsave(save_root / 'label' / f'{count}.png', clear(img[i]), cmap='gray')\n",
    "            plt.imsave(save_root / 'recon' / f'{count}.png', clear(recon_img), cmap='gray')\n",
    "            np.save(str(save_root / 'input' / f'{count}.npy'), clear(under_img[i], normalize=False))\n",
    "            np.save(str(save_root / 'recon' / f'{count}.npy'), clear(x[i], normalize=False))\n",
    "            np.save(str(save_root / 'label' / f'{count}.npy'), clear(img[i], normalize=False))\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 240, 240])\n"
     ]
    }
   ],
   "source": [
    "print(img.size())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MRI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
